import gin.torch.external_configurables
import famews.train.pipeline
import famews.data.datasets
import famews.models.encoders
import famews.train.sequence
import famews.train.utils

# Model Parameter
NUM_CLASSES = 1
EPOCHS = 100000
DEPTH = 4
NUM_LEAVES = 16
SUBSAMPLE_DATA = 0.33
SUBSAMPLE_FEAT = 0.33
BAGGING_FREQ  = 1
MIN_CHILD_LEAF = 1000


TASK = 'Dynamic_CircFailure_8Hours' # Dynamic_CircFailure_12Hours
ACC = 'cpu'
WORKERS = -1

# Data Parameter
RES = 1
RES_LAB = 1
MAXLEN = 2016
DATA_PATH = "{...}/ml_stage/{data}.h5"

# Dataset
ICUVariableLengthDataset.maxlen = %MAXLEN
# ICUVariableLengthDataset.feature_load_full_ram = True
ICUVariableLengthDataset.subsample_train = 0.25
ICUVariableLengthDataset.feature_datatype = 'float32'

ICUVariableLengthLoaderTables.splits = ['train','test','val']
ICUVariableLengthLoaderTables.task = %TASK
ICUVariableLengthLoaderTables.data_resampling = %RES
ICUVariableLengthLoaderTables.label_resampling = %RES_LAB
ICUVariableLengthLoaderTables.on_RAM = False
ICUVariableLengthLoaderTables.use_feat = True # load and use the extracted feature

# MLTrainPipeline
MLTrainPipeline.do_train = False
MLTrainPipeline.do_test = False
MLTrainPipeline.stages = [@VariableSelectionSK]
# MLTrainPipeline.columns = ['ABPm','Spitzendruck','a_Lac','min_FIO2','n_meas_GCS Motorik']

# SetupTrain Stage
SetupTrainSK.model = @LGBMClassifier()
SetupTrainSK.dataset_class = @ICUVariableLengthDataset
SetupTrainSK.wrapper_class = @TabularWrapper
SetupTrainSK.data_path = %DATA_PATH

# TrainWithSK Stage
TrainWithSK.max_iter = %EPOCHS
TrainWithSK.num_workers = %WORKERS
TrainWithSK.class_weights = None
TrainWithSK.accelerator = %ACC
TrainWithSK.early_stopping_patience = 20

# TestModelSK Stage
TestModelSK.accelerator = %ACC
TestModelSK.num_workers = %WORKERS

# Training Wrapper
TabularWrapper.task = 'classification/binary'

# Encoder params
LGBMClassifier.max_depth = %DEPTH
LGBMClassifier.num_leaves = %NUM_LEAVES
LGBMClassifier.n_estimators = %EPOCHS
LGBMClassifier.min_child_samples = %MIN_CHILD_LEAF
LGBMClassifier.subsample = %SUBSAMPLE_DATA
LGBMClassifier.subsample_freq = %BAGGING_FREQ
LGBMClassifier.colsample_bytree = %SUBSAMPLE_FEAT

# Variable Selection
VariableSelectionSK.top_k = 500 # Top K features to select
# VariableSelectionSK.importance_model = @importance/RandomForestClassifier
VariableSelectionSK.importance_model = @importance/GradientBoostingClassifier

# importance/RandomForestClassifier.n_jobs = 4
# importance/RandomForestClassifier.n_estimators = 100
# importance/RandomForestClassifier.verbose = 1

importance/GradientBoostingClassifier.n_estimators = 100 # 100
importance/GradientBoostingClassifier.loss = 'log_loss'
importance/GradientBoostingClassifier.verbose = 1